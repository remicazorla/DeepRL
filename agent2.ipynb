{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f15e92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "B:\\Anaconda\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import tensortrade.env.default as default\n",
    "from tensortrade.oms.exchanges import Exchange\n",
    "from tensortrade.feed import Stream\n",
    "from tensortrade.oms.services.execution.simulated import execute_order\n",
    "from tensortrade.feed.core import Stream, DataFeed, NameSpace\n",
    "from tensortrade.oms.wallets import Wallet, Portfolio\n",
    "from tensortrade.oms.instruments import Instrument\n",
    "from tensortrade.agents import DQNAgent\n",
    "from tensortrade.env.default.actions import BSH, ManagedRiskOrders\n",
    "from tensortrade.env.default.rewards import RiskAdjustedReturns\n",
    "from tensortrade.env.default.renderers import PlotlyTradingChart\n",
    "from all_indicators import get_all_stock_indicators\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.options.mode.use_inf_as_na = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "599aecf6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_all_stock_indicators' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 1\u001b[1;36m\n\u001b[1;33m    TKO_data = get_all_stock_indicators('TKO.PA')\u001b[1;36m\n",
      "\u001b[1;31mNameError\u001b[0m\u001b[1;31m:\u001b[0m name 'get_all_stock_indicators' is not defined\n"
     ]
    }
   ],
   "source": [
    "TKO_data = get_all_stock_indicators('TKO.PA')\n",
    "STM_data = get_all_stock_indicators('STM.PA')\n",
    "THEP_data = get_all_stock_indicators('THEP.PA')\n",
    "BIM_data = get_all_stock_indicators('BIM.PA')\n",
    "ERF_data = get_all_stock_indicators('ERF.PA')\n",
    "TRI_data = get_all_stock_indicators('TRI.PA')\n",
    "VIRP_data = get_all_stock_indicators('VIRP.PA')\n",
    "AI_data = get_all_stock_indicators('AI.PA')\n",
    "SU_data = get_all_stock_indicators('SU.PA')\n",
    "LTA_data = get_all_stock_indicators('LTA.PA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ffb8dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_var = pd.read_excel('feature_selection.xlsx', sheet_name='ALL')\n",
    "\n",
    "def drop_corr_col(stock_data, ticker):\n",
    "    relevant_cols = selected_var[ticker].dropna()\n",
    "    relevant_cols = relevant_cols[relevant_cols!='Sortino 10']\n",
    "    filtered_data = stock_data.copy().drop(columns=['Open', 'High', 'Low', 'Close', 'Volume','Returns','Log Returns'])\n",
    "    filtered_data = filtered_data[relevant_cols]\n",
    "    corr_matrix = filtered_data.corr()\n",
    "    upperMatrix = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "    corrFeatures = [column for column in upperMatrix.columns if any(upperMatrix[column] > 0.95)]\n",
    "    print(corrFeatures)\n",
    "    return pd.concat([filtered_data.drop(columns=corrFeatures),stock_data[['Open', 'High', 'Low', 'Close', 'Volume','Returns','Log Returns']]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c276b986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trend_vortex_ind_diff', 'Sharpe 14', 'Sharpe 18', 'Sharpe 16', 'Beta 24']\n",
      "['Sharpe 12']\n",
      "['Sharpe 18']\n",
      "['Sharpe 14', 'Sharpe 16', 'Sharpe 18', 'Sortino 24', 'Sortino 26', 'Beta 24']\n",
      "['Sharpe 126', 'Sortino 24', 'Sharpe 16']\n",
      "[]\n",
      "['Sortino 22']\n",
      "['Sharpe 16', 'Sortino 18']\n",
      "['Sortino 16', 'Sharpe 18']\n",
      "['volatility_bbh', 'Sortino 126', 'trend_ichimoku_b', 'rsi10']\n"
     ]
    }
   ],
   "source": [
    "selected_STM_data = drop_corr_col(STM_data, 'STM')\n",
    "selected_THEP_data = drop_corr_col(THEP_data, 'THEP')\n",
    "selected_BIM_data = drop_corr_col(BIM_data, 'BIM')\n",
    "selected_TKO_data = drop_corr_col(TKO_data, 'TKO')\n",
    "selected_ERF_data = drop_corr_col(ERF_data, 'ERF')\n",
    "selected_TRI_data = drop_corr_col(TRI_data, 'TRI')\n",
    "selected_VIRP_data = drop_corr_col(VIRP_data, 'VIRP')\n",
    "selected_AI_data = drop_corr_col(AI_data, 'AI')\n",
    "selected_SU_data = drop_corr_col(SU_data, 'SU')\n",
    "selected_LTA_data = drop_corr_col(LTA_data, 'LTA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03d84bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(data):\n",
    "    X = data.copy().drop(columns=['Log Returns','Returns'])\n",
    "    y = data.copy()['Returns']\n",
    "\n",
    "    X_train_test, X_valid, y_train_test, y_valid = \\\n",
    "        train_test_split(X, y, train_size=0.8, test_size=0.2, shuffle=False)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X_train_test, y_train_test, train_size=0.7, test_size=0.3, shuffle=False)\n",
    "\n",
    "    return X_train, X_test, X_valid, y_train, y_test, y_valid\n",
    "\n",
    "TKO_X_train, TKO_X_test, TKO_X_valid, TKO_y_train, TKO_y_test, TKO_y_valid = split_data(selected_TKO_data)\n",
    "STM_X_train, STM_X_test, STM_X_valid, STM_y_train, STM_y_test, STM_y_valid = split_data(selected_STM_data)\n",
    "THEP_X_train, THEP_X_test, THEP_X_valid, THEP_y_train, THEP_y_test, THEP_y_valid = split_data(selected_THEP_data)\n",
    "BIM_X_train, BIM_X_test, BIM_X_valid, BIM_y_train, BIM_y_test, BIM_y_valid = split_data(selected_BIM_data)\n",
    "ERF_X_train, ERF_X_test, ERF_X_valid, ERF_y_train, ERF_y_test, ERF_y_valid = split_data(selected_ERF_data)\n",
    "TRI_X_train, TRI_X_test, TRI_X_valid, TRI_y_train, TRI_y_test, TRI_y_valid = split_data(selected_TRI_data)\n",
    "VIRP_X_train, VIRP_X_test, VIRP_X_valid, VIRP_y_train, VIRP_y_test, VIRP_y_valid = split_data(selected_VIRP_data)\n",
    "AI_X_train, AI_X_test, AI_X_valid, AI_y_train, AI_y_test, AI_y_valid = split_data(selected_AI_data)\n",
    "SU_X_train, SU_X_test, SU_X_valid, SU_y_train, SU_y_test, SU_y_valid = split_data(selected_SU_data)\n",
    "LTA_X_train, LTA_X_test, LTA_X_valid, LTA_y_train, LTA_y_test, LTA_y_valid = split_data(selected_LTA_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65bc7c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "cwd = os.getcwd()\n",
    "\n",
    "TKO_train_pickle = os.path.join(cwd, 'TKO_X_train.pickle')\n",
    "STM_train_pickle = os.path.join(cwd, 'STM_X_train.pickle')\n",
    "THEP_train_pickle = os.path.join(cwd, 'THEP_X_train.pickle')\n",
    "BIM_train_pickle = os.path.join(cwd, 'BIM_X_train.pickle')\n",
    "ERF_train_pickle = os.path.join(cwd, 'ERF_X_train.pickle')\n",
    "TRI_train_pickle = os.path.join(cwd, 'TRI_X_train.pickle')\n",
    "VIRP_train_pickle = os.path.join(cwd, 'VIRP_X_train.pickle')\n",
    "AI_train_pickle = os.path.join(cwd, 'AI_X_train.pickle')\n",
    "SU_train_pickle = os.path.join(cwd, 'SU_X_train.pickle')\n",
    "LTA_train_pickle = os.path.join(cwd, 'LTA_X_train.pickle')\n",
    "TKO_test_pickle = os.path.join(cwd, 'TKO_X_test.pickle')\n",
    "STM_test_pickle = os.path.join(cwd, 'STM_X_test.pickle')\n",
    "THEP_test_pickle = os.path.join(cwd, 'THEP_X_test.pickle')\n",
    "BIM_test_pickle = os.path.join(cwd, 'BIM_X_test.pickle')\n",
    "ERF_test_pickle = os.path.join(cwd, 'ERF_X_test.pickle')\n",
    "TRI_test_pickle = os.path.join(cwd, 'TRI_X_test.pickle')\n",
    "VIRP_test_pickle = os.path.join(cwd, 'VIRP_X_test.pickle')\n",
    "AI_test_pickle = os.path.join(cwd, 'AI_X_test.pickle')\n",
    "SU_test_pickle = os.path.join(cwd, 'SU_X_test.pickle')\n",
    "LTA_test_pickle = os.path.join(cwd, 'LTA_X_test.pickle')\n",
    "\n",
    "TKO_X_train.to_pickle(TKO_train_pickle)\n",
    "STM_X_train.to_pickle(STM_train_pickle)\n",
    "THEP_X_train.to_pickle(THEP_train_pickle)\n",
    "BIM_X_train.to_pickle(BIM_train_pickle)\n",
    "ERF_X_train.to_pickle(ERF_train_pickle)\n",
    "TRI_X_train.to_pickle(TRI_train_pickle)\n",
    "VIRP_X_train.to_pickle(VIRP_train_pickle)\n",
    "AI_X_train.to_pickle(AI_train_pickle)\n",
    "SU_X_train.to_pickle(SU_train_pickle)\n",
    "LTA_X_train.to_pickle(LTA_train_pickle)\n",
    "TKO_X_test.to_pickle(TKO_test_pickle)\n",
    "STM_X_test.to_pickle(STM_test_pickle)\n",
    "THEP_X_test.to_pickle(THEP_test_pickle)\n",
    "BIM_X_test.to_pickle(BIM_test_pickle)\n",
    "ERF_X_test.to_pickle(ERF_test_pickle)\n",
    "TRI_X_test.to_pickle(TRI_test_pickle)\n",
    "VIRP_X_test.to_pickle(VIRP_test_pickle)\n",
    "AI_X_test.to_pickle(AI_test_pickle)\n",
    "SU_X_test.to_pickle(SU_test_pickle)\n",
    "LTA_X_test.to_pickle(LTA_test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "807e1951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "cwd = os.getcwd()\n",
    "\n",
    "TKO_train_pickle = os.path.join(cwd, 'TKO_X_train.pickle')\n",
    "STM_train_pickle = os.path.join(cwd, 'STM_X_train.pickle')\n",
    "THEP_train_pickle = os.path.join(cwd, 'THEP_X_train.pickle')\n",
    "BIM_train_pickle = os.path.join(cwd, 'BIM_X_train.pickle')\n",
    "ERF_train_pickle = os.path.join(cwd, 'ERF_X_train.pickle')\n",
    "TRI_train_pickle = os.path.join(cwd, 'TRI_X_train.pickle')\n",
    "VIRP_train_pickle = os.path.join(cwd, 'VIRP_X_train.pickle')\n",
    "AI_train_pickle = os.path.join(cwd, 'AI_X_train.pickle')\n",
    "SU_train_pickle = os.path.join(cwd, 'SU_X_train.pickle')\n",
    "LTA_train_pickle = os.path.join(cwd, 'LTA_X_train.pickle')\n",
    "TKO_test_pickle = os.path.join(cwd, 'TKO_X_test.pickle')\n",
    "STM_test_pickle = os.path.join(cwd, 'STM_X_test.pickle')\n",
    "THEP_test_pickle = os.path.join(cwd, 'THEP_X_test.pickle')\n",
    "BIM_test_pickle = os.path.join(cwd, 'BIM_X_test.pickle')\n",
    "ERF_test_pickle = os.path.join(cwd, 'ERF_X_test.pickle')\n",
    "TRI_test_pickle = os.path.join(cwd, 'TRI_X_test.pickle')\n",
    "VIRP_test_pickle = os.path.join(cwd, 'VIRP_X_test.pickle')\n",
    "AI_test_pickle = os.path.join(cwd, 'AI_X_test.pickle')\n",
    "SU_test_pickle = os.path.join(cwd, 'SU_X_test.pickle')\n",
    "LTA_test_pickle = os.path.join(cwd, 'LTA_X_test.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "171c646b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_render_features(stock_data, ticker):\n",
    "    #ohlc prices for render\n",
    "    stock_ohlc = stock_data[['Open','High','Low','Close','Volume']].copy()\n",
    "    stock_ohlc['date'] = stock_ohlc.index + pd.DateOffset(hours=2)\n",
    "    stock_ohlc = stock_ohlc.add_prefix(f\"{ticker}:\")\n",
    "    \n",
    "    #all features to train from + minmax scaling\n",
    "    scaler = MinMaxScaler()\n",
    "    stock_features = stock_data.copy()\n",
    "    stock_features = stock_features.add_prefix(f\"{ticker}:\")\n",
    "    scaler.fit(stock_features)\n",
    "    stock_features_scaled = pd.DataFrame(scaler.fit_transform(stock_features), columns = stock_features.columns, index = stock_features.index)\n",
    "    return stock_ohlc, stock_features_scaled\n",
    "\n",
    "def get_price_stream(stock_renders, tickers): #list\n",
    "    stock_price_stream_list = []\n",
    "    for i in range(len(stock_renders)):\n",
    "        stock_price_stream_list.append(Stream.source(list(stock_renders[i][f\"{tickers[i]}:Close\"]), dtype=\"float\").rename(f\"EUR-{tickers[i].replace('.PA', '')}\"))\n",
    "    return stock_price_stream_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "138a3036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_env(config):\n",
    "    TKO_data = pd.read_pickle(config['TKO_filename'])\n",
    "    STM_data = pd.read_pickle(config['STM_filename'])\n",
    "    THEP_data = pd.read_pickle(config['THEP_filename'])\n",
    "    BIM_data = pd.read_pickle(config['BIM_filename'])\n",
    "    ERF_data = pd.read_pickle(config['ERF_filename'])\n",
    "    TRI_data = pd.read_pickle(config['TRI_filename'])\n",
    "    VIRP_data = pd.read_pickle(config['VIRP_filename'])\n",
    "    AI_data = pd.read_pickle(config['AI_filename'])\n",
    "    SU_data = pd.read_pickle(config['SU_filename'])\n",
    "    LTA_data = pd.read_pickle(config['LTA_filename'])\n",
    "    \n",
    "    TKO_render, TKO_scaled_features = separate_render_features(TKO_data, 'TKO.PA')\n",
    "    STM_render, STM_scaled_features = separate_render_features(STM_data, 'STM.PA')\n",
    "    THEP_render, THEP_scaled_features = separate_render_features(THEP_data, 'THEP.PA')\n",
    "    BIM_render, BIM_scaled_features = separate_render_features(BIM_data, 'BIM.PA')   \n",
    "    ERF_render, ERF_scaled_features = separate_render_features(ERF_data, 'ERF.PA')\n",
    "    TRI_render, TRI_scaled_features = separate_render_features(TRI_data, 'TRI.PA')\n",
    "    VIRP_render, VIRP_scaled_features = separate_render_features(VIRP_data, 'VIRP.PA')\n",
    "    AI_render, AI_scaled_features = separate_render_features(AI_data, 'AI.PA')       \n",
    "    SU_render, SU_scaled_features = separate_render_features(SU_data, 'SU.PA')\n",
    "    LTA_render, LTA_scaled_features = separate_render_features(LTA_data, 'LTA.PA')     \n",
    "    \n",
    "    price_streams = get_price_stream([TKO_render, STM_render, THEP_render, BIM_render, ERF_render, TRI_render, VIRP_render, AI_render, SU_render, LTA_render], [\"TKO.PA\", \"STM.PA\", \"THEP.PA\", \"BIM.PA\", \"ERF.PA\", \"TRI.PA\",\"VIRP.PA\", \"AI.PA\", \"SU.PA\", \"LTA.PA\"])\n",
    "    euronext = Exchange('euronext', service=execute_order)(price_streams[0], price_streams[1], price_streams[2], price_streams[3], price_streams[4], price_streams[5], price_streams[6], price_streams[7], price_streams[8], price_streams[9])\n",
    "\n",
    "    all_scaled_features = pd.concat([TKO_scaled_features, STM_scaled_features, THEP_scaled_features, BIM_scaled_features, ERF_scaled_features, TRI_scaled_features, VIRP_scaled_features, AI_scaled_features, SU_scaled_features, LTA_scaled_features], axis=1)\n",
    "    with NameSpace(\"euronext\"):\n",
    "        features = [Stream.source(list(all_scaled_features[feature]), dtype=\"float\").rename(feature) for feature in all_scaled_features.columns]\n",
    "    all_features_feed = DataFeed(features)\n",
    "    all_features_feed.compile()\n",
    "\n",
    "    EUR = Instrument('EUR', 4, 'Euro')\n",
    "    TKO = Instrument('TKO', 4, 'Tikehau')\n",
    "    STM = Instrument('STM', 4, 'STMicroelectronics')\n",
    "    THEP = Instrument('THEP', 4, 'Thermador')\n",
    "    BIM = Instrument('BIM', 4, 'Biomerieux')\n",
    "    ERF = Instrument('ERF', 4, 'Eurofins')\n",
    "    TRI = Instrument('TRI', 4, 'Trigano')\n",
    "    VIRP = Instrument('VIRP', 4, 'Virbac')\n",
    "    AI = Instrument('AI', 4, 'Air Liquide')\n",
    "    SU = Instrument('SU', 4, 'Schneider Electric')\n",
    "    LTA = Instrument('LTA', 4, 'Altamir')\n",
    "    \n",
    "    cash = Wallet(euronext, 10000 * EUR)\n",
    "    asset_tko = Wallet(euronext, 0 * TKO)\n",
    "    asset_stm = Wallet(euronext, 0 * STM)\n",
    "    asset_thep = Wallet(euronext, 0 * THEP)\n",
    "    asset_bim = Wallet(euronext, 0 * BIM)\n",
    "    asset_erf = Wallet(euronext, 0 * ERF)\n",
    "    asset_tri = Wallet(euronext, 0 * TRI)\n",
    "    asset_virp = Wallet(euronext, 0 * VIRP)\n",
    "    asset_ai = Wallet(euronext, 0 * AI)\n",
    "    asset_su = Wallet(euronext, 0 * SU)\n",
    "    asset_lta = Wallet(euronext, 0 * LTA)\n",
    "    \n",
    "    portfolio = Portfolio(EUR, [cash, asset_tko, asset_stm, asset_thep, asset_bim, asset_erf, asset_tri, asset_virp, asset_ai, asset_su, asset_lta])\n",
    "\n",
    "    reward_scheme = RiskAdjustedReturns(return_algorithm='sortino', window_size=75)\n",
    "    action_scheme = ManagedRiskOrders()\n",
    "\n",
    "    chart_renderer = PlotlyTradingChart(\n",
    "        display=True,  # show the chart on screen (default)\n",
    "        height=800,  # affects both displayed and saved file height. None for 100% height.\n",
    "        save_format=\"html\",  # save the chart to an HTML file\n",
    "        auto_open_html=True,  # open the saved HTML chart in a new browser tab\n",
    "    )\n",
    "    \n",
    "    renderer_feed = DataFeed([\n",
    "        Stream.source(list(TKO_render[\"TKO.PA:date\"])).rename(\"date\"),\n",
    "        Stream.source(list(TKO_render[\"TKO.PA:Open\"]), dtype=\"float\").rename(\"open\"),\n",
    "        Stream.source(list(TKO_render[\"TKO.PA:High\"]), dtype=\"float\").rename(\"high\"),\n",
    "        Stream.source(list(TKO_render[\"TKO.PA:Low\"]), dtype=\"float\").rename(\"low\"),\n",
    "        Stream.source(list(TKO_render[\"TKO.PA:Close\"]), dtype=\"float\").rename(\"close\"), \n",
    "        Stream.source(list(TKO_render[\"TKO.PA:Volume\"]), dtype=\"float\").rename(\"volume\"),\n",
    "    ])\n",
    "\n",
    "    env = default.create(\n",
    "        portfolio=portfolio,\n",
    "        action_scheme=action_scheme,\n",
    "        reward_scheme=reward_scheme,\n",
    "        feed=all_features_feed,\n",
    "        renderer_feed=renderer_feed,\n",
    "        renderer=chart_renderer,\n",
    "        window_size=config[\"window_size\"],\n",
    "        max_allowed_loss=config[\"max_allowed_loss\"]\n",
    "    )\n",
    "    \n",
    "    return env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bc94246",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-15 22:05:09,704\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "ray.init(num_cpus=4,\n",
    "         include_dashboard=True,\n",
    "         ignore_reinit_error=True)\n",
    "\n",
    "register_env(\"TradingEnv\", create_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a9b15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\remik\\AppData\\Local\\Temp\\ipykernel_12952\\1214262178.py:2: DeprecationWarning: The module `ray.tune.suggest` has been moved to `ray.tune.search` and the old location will be deprecated soon. Please adjust your imports to point to the new location. Example: Do a global search and replace `ray.tune.suggest` with `ray.tune.search`.\n",
      "  from ray.tune.suggest import ConcurrencyLimiter\n",
      "C:\\Users\\remik\\AppData\\Local\\Temp\\ipykernel_12952\\1214262178.py:3: DeprecationWarning: The module `ray.tune.suggest.optuna` has been moved to `ray.tune.search.optuna` and the old location will be deprecated soon. Please adjust your imports to point to the new location. Example: Do a global search and replace `ray.tune.suggest.optuna` with `ray.tune.search.optuna`.\n",
      "  from ray.tune.suggest.optuna import OptunaSearch\n",
      "\u001b[32m[I 2022-12-15 22:05:12,837]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n",
      "2022-12-15 22:05:12,864\tINFO trial_runner.py:683 -- No local checkpoint was found. Ray Tune will now start a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2022-12-16 02:33:30</td></tr>\n",
       "<tr><td>Running for: </td><td>04:28:17.44        </td></tr>\n",
       "<tr><td>Memory:      </td><td>13.0/16.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: -2072386.1339745852 | Iter 1.000: -1234128.7516866443<br>Resources requested: 3.0/4 CPUs, 0/1 GPUs, 0.0/2.11 GiB heap, 0.0/1.06 GiB objects\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  entropy_coeff</th><th style=\"text-align: right;\">   gamma</th><th style=\"text-align: right;\">  lambda</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  vf_loss_coeff</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">     reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_TradingEnv_884a7705</td><td>RUNNING </td><td>127.0.0.1:14040</td><td style=\"text-align: right;\">    6.54801e-05</td><td style=\"text-align: right;\">0.899658</td><td style=\"text-align: right;\">0.763905</td><td style=\"text-align: right;\">0.00080007 </td><td style=\"text-align: right;\">       0.543037</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         15333.3</td><td style=\"text-align: right;\">60000</td><td style=\"text-align: right;\">-1.4482e+06</td><td style=\"text-align: right;\">              908515</td><td style=\"text-align: right;\">        -1.18284e+07</td><td style=\"text-align: right;\">            499.11</td></tr>\n",
       "<tr><td>PPO_TradingEnv_c8a9304a</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">    0.0201308  </td><td style=\"text-align: right;\">0.924833</td><td style=\"text-align: right;\">0.62278 </td><td style=\"text-align: right;\">8.24307e-05</td><td style=\"text-align: right;\">       0.695587</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14040)\u001b[0m Windows fatal exception: code 0xc0000139\n",
      "\u001b[2m\u001b[36m(pid=14040)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14040)\u001b[0m Windows fatal exception: code 0xc0000139\n",
      "\u001b[2m\u001b[36m(pid=14040)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14040)\u001b[0m Windows fatal exception: code 0xc0000139\n",
      "\u001b[2m\u001b[36m(pid=14040)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14040)\u001b[0m B:\\Anaconda\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "\u001b[2m\u001b[36m(pid=14040)\u001b[0m   warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "\u001b[2m\u001b[36m(pid=14040)\u001b[0m Windows fatal exception: code 0xc0000139\n",
      "\u001b[2m\u001b[36m(pid=14040)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14040)\u001b[0m Windows fatal exception: code 0xc0000139\n",
      "\u001b[2m\u001b[36m(pid=14040)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14040)\u001b[0m Windows fatal exception: code 0xc0000139\n",
      "\u001b[2m\u001b[36m(pid=14040)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14040)\u001b[0m WARNING:tensorflow:From B:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:561: calling function (from tensorflow.python.eager.def_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=14040)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=14040)\u001b[0m experimental_relax_shapes is deprecated, use reduce_retracing instead\n",
      "\u001b[2m\u001b[36m(pid=14040)\u001b[0m B:\\Anaconda\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "\u001b[2m\u001b[36m(pid=14040)\u001b[0m   \"class\": algorithms.Blowfish,\n",
      "\u001b[2m\u001b[36m(PPO pid=14040)\u001b[0m 2022-12-15 22:05:21,684\tWARNING algorithm_config.py:488 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(PPO pid=14040)\u001b[0m 2022-12-15 22:05:22,602\tINFO algorithm.py:501 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=24044)\u001b[0m Windows fatal exception: code 0xc0000139\n",
      "\u001b[2m\u001b[36m(pid=24044)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=24044)\u001b[0m Windows fatal exception: code 0xc0000139\n",
      "\u001b[2m\u001b[36m(pid=24044)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=24044)\u001b[0m Windows fatal exception: code 0xc0000139\n",
      "\u001b[2m\u001b[36m(pid=24044)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=24044)\u001b[0m B:\\Anaconda\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "\u001b[2m\u001b[36m(pid=24044)\u001b[0m   warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "\u001b[2m\u001b[36m(pid=22764)\u001b[0m Windows fatal exception: code 0xc0000139\n",
      "\u001b[2m\u001b[36m(pid=22764)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=22764)\u001b[0m Windows fatal exception: code 0xc0000139\n",
      "\u001b[2m\u001b[36m(pid=22764)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=22764)\u001b[0m Windows fatal exception: code 0xc0000139\n",
      "\u001b[2m\u001b[36m(pid=22764)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=22764)\u001b[0m B:\\Anaconda\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "\u001b[2m\u001b[36m(pid=22764)\u001b[0m   warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "\u001b[2m\u001b[36m(pid=22764)\u001b[0m Windows fatal exception: code 0xc0000139\n",
      "\u001b[2m\u001b[36m(pid=22764)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=22764)\u001b[0m Windows fatal exception: code 0xc0000139\n",
      "\u001b[2m\u001b[36m(pid=22764)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=22764)\u001b[0m Windows fatal exception: code 0xc0000139\n",
      "\u001b[2m\u001b[36m(pid=22764)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=24044)\u001b[0m Windows fatal exception: code 0xc0000139\n",
      "\u001b[2m\u001b[36m(pid=24044)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=24044)\u001b[0m Windows fatal exception: code 0xc0000139\n",
      "\u001b[2m\u001b[36m(pid=24044)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=24044)\u001b[0m Windows fatal exception: code 0xc0000139\n",
      "\u001b[2m\u001b[36m(pid=24044)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=22764)\u001b[0m WARNING:tensorflow:From B:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:561: calling function (from tensorflow.python.eager.def_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=22764)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=22764)\u001b[0m experimental_relax_shapes is deprecated, use reduce_retracing instead\n",
      "\u001b[2m\u001b[36m(pid=24044)\u001b[0m WARNING:tensorflow:From B:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:561: calling function (from tensorflow.python.eager.def_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=24044)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=24044)\u001b[0m experimental_relax_shapes is deprecated, use reduce_retracing instead\n",
      "\u001b[2m\u001b[36m(pid=24044)\u001b[0m B:\\Anaconda\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "\u001b[2m\u001b[36m(pid=24044)\u001b[0m   \"class\": algorithms.Blowfish,\n",
      "\u001b[2m\u001b[36m(pid=22764)\u001b[0m B:\\Anaconda\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "\u001b[2m\u001b[36m(pid=22764)\u001b[0m   \"class\": algorithms.Blowfish,\n",
      "\u001b[2m\u001b[36m(PPO pid=14040)\u001b[0m 2022-12-15 22:05:32,962\tINFO trainable.py:172 -- Trainable.setup took 10.362 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(PPO pid=14040)\u001b[0m 2022-12-15 22:05:32,963\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th style=\"text-align: right;\">  agent_timesteps_total</th><th>counters                                                                                                                            </th><th>custom_metrics  </th><th>date               </th><th>done  </th><th style=\"text-align: right;\">  episode_len_mean</th><th>episode_media  </th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_mean</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episodes_this_iter</th><th style=\"text-align: right;\">  episodes_total</th><th>evaluation                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </th><th>experiment_id                   </th><th>hostname       </th><th>info                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip  </th><th style=\"text-align: right;\">  num_agent_steps_sampled</th><th style=\"text-align: right;\">  num_agent_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_sampled</th><th style=\"text-align: right;\">  num_env_steps_sampled_this_iter</th><th style=\"text-align: right;\">  num_env_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_trained_this_iter</th><th style=\"text-align: right;\">  num_faulty_episodes</th><th style=\"text-align: right;\">  num_healthy_workers</th><th style=\"text-align: right;\">  num_in_flight_async_reqs</th><th style=\"text-align: right;\">  num_remote_worker_restarts</th><th style=\"text-align: right;\">  num_steps_trained_this_iter</th><th>perf                                                                           </th><th style=\"text-align: right;\">  pid</th><th>policy_reward_max  </th><th>policy_reward_mean  </th><th>policy_reward_min  </th><th>sampler_perf                                                                                                                                                                                                  </th><th>sampler_results                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th>timers                                                                                                                                                                                   </th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th style=\"text-align: right;\">  timesteps_total</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id  </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_TradingEnv_884a7705</td><td style=\"text-align: right;\">                  60000</td><td>{&#x27;num_env_steps_sampled&#x27;: 60000, &#x27;num_env_steps_trained&#x27;: 60000, &#x27;num_agent_steps_sampled&#x27;: 60000, &#x27;num_agent_steps_trained&#x27;: 60000}</td><td>{}              </td><td>2022-12-16_02-21-08</td><td>False </td><td style=\"text-align: right;\">            499.11</td><td>{}             </td><td style=\"text-align: right;\">              908515</td><td style=\"text-align: right;\">          -1.4482e+06</td><td style=\"text-align: right;\">        -1.18284e+07</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">             118</td><td>{&#x27;episode_reward_max&#x27;: 2.2871541084603124, &#x27;episode_reward_min&#x27;: 2.2871541084603124, &#x27;episode_reward_mean&#x27;: 2.287154108460313, &#x27;episode_len_mean&#x27;: 247.0, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 10, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [2.2871541084603124, 2.2871541084603124, 2.2871541084603124, 2.2871541084603124, 2.2871541084603124, 2.2871541084603124, 2.2871541084603124, 2.2871541084603124, 2.2871541084603124, 2.2871541084603124], &#x27;episode_lengths&#x27;: [247, 247, 247, 247, 247, 247, 247, 247, 247, 247]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 0.7540129742665231, &#x27;mean_inference_ms&#x27;: 5.815279164947077, &#x27;mean_action_processing_ms&#x27;: 0.08066226710790836, &#x27;mean_env_wait_ms&#x27;: 5.322742924182278, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0, &#x27;num_agent_steps_sampled_this_iter&#x27;: 2470, &#x27;num_env_steps_sampled_this_iter&#x27;: 2470, &#x27;timesteps_this_iter&#x27;: 2470, &#x27;num_healthy_workers&#x27;: 0, &#x27;num_in_flight_async_reqs&#x27;: 0, &#x27;num_remote_worker_restarts&#x27;: 0}</td><td>7b4a25127b3943c0abd2fdacbbba4f73</td><td>DESKTOP-N80GTVU</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;allreduce_latency&#x27;: 0.0, &#x27;grad_gnorm&#x27;: 2.261252175800262, &#x27;cur_kl_coeff&#x27;: 0.6750000000000002, &#x27;cur_lr&#x27;: 5.4e-05, &#x27;total_loss&#x27;: 1.7451124548871992, &#x27;policy_loss&#x27;: -0.1929711052985807, &#x27;vf_loss&#x27;: 3.55090096789983, &#x27;vf_explained_var&#x27;: 0.3938513953198669, &#x27;kl&#x27;: 0.015172046910756323, &#x27;entropy&#x27;: 6.545931939668553, &#x27;entropy_coeff&#x27;: 6.548005712148715e-05}, &#x27;model&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;num_agent_steps_trained&#x27;: 128.0, &#x27;num_grad_updates_lifetime&#x27;: 13485.5, &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: 464.5}}, &#x27;num_env_steps_sampled&#x27;: 60000, &#x27;num_env_steps_trained&#x27;: 60000, &#x27;num_agent_steps_sampled&#x27;: 60000, &#x27;num_agent_steps_trained&#x27;: 60000}</td><td style=\"text-align: right;\">                        15</td><td>127.0.0.1</td><td style=\"text-align: right;\">                    60000</td><td style=\"text-align: right;\">                    60000</td><td style=\"text-align: right;\">                  60000</td><td style=\"text-align: right;\">                             4000</td><td style=\"text-align: right;\">                  60000</td><td style=\"text-align: right;\">                             4000</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    2</td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                         4000</td><td>{&#x27;cpu_util_percent&#x27;: 13.247117437722418, &#x27;ram_util_percent&#x27;: 77.66163701067616}</td><td style=\"text-align: right;\">14040</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 0.8659172322685121, &#x27;mean_inference_ms&#x27;: 5.928027824295603, &#x27;mean_action_processing_ms&#x27;: 0.08317311804656224, &#x27;mean_env_wait_ms&#x27;: 5.859601344632639, &#x27;mean_env_render_ms&#x27;: 0.0}</td><td>{&#x27;episode_reward_max&#x27;: 908515.1695934841, &#x27;episode_reward_min&#x27;: -11828426.45343953, &#x27;episode_reward_mean&#x27;: -1448196.865156557, &#x27;episode_len_mean&#x27;: 499.11, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 6, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [544744.0979353177, 4.962960878978196, -3.6728501747230626, 908512.5543750048, 2.1451596254984207, -305867.68361139763, 2.340083068650213, -229301.2290854197, -6362842.39160595, -1.6350130045119897, -1.0629755377860717, -11828426.45343953, -829818.5043064441, -6362843.559804704, -2.3373139258891027, -3682768.640156774, -621160.9144779942, 1.9333363855068233, -1.2363862697255652, -229298.8216918868, 2.005998224835111, -1659634.2431659705, -2.3558148474197322, -829814.9149024892, -10045720.79154185, -2.1730162214367432, 1.7037637544483595, -2455314.6490741284, 5.9197636369383915, -2.669644352986526, -2.6572131484546144, -4771525.606843529, 6.512443879679798, 7.306836801096442, 1.099845368310329, -7097081.33195929, 0.18956428417013804, 908515.1695934841, -3.76528446572991, -1364340.8262666077, 5.835432943894992, -6362844.443555433, -207329.21139405115, -2455311.8642393243, -3346175.6144329575, -2509487.818170578, -1.6247942391796004, 1.5068604968517605, 2.6931201351406293, -3.5765438180778566, -341143.56496863026, -305867.16454337025, -1659633.3998778323, -4.184955398884721, -1659632.5219742367, -10045718.42407454, 0.943859564048431, -0.7449982334372525, 3.4509784268373958, -6362846.078692837, -0.19622176093314278, 2.5964697747346355, -1227662.0571876147, -0.5129660797431888, 6.868608247463773, 1.1036885555264768, 5.769199725309511, 1.979468877783157, -2074540.8402101991, -10045716.454932787, -1227653.1954664357, -1.9913262317308822, 1.3655121399594008, -207327.47744549206, -11828425.883645982, -2.6880947530949286, -4.579284585100158, -8036422.29883893, -4018602.4081828385, -1364347.1179305834, -2.381456555709262, -1.4494699680808194, -2009303.7105173697, -3.1617353865410527, -1.6289563975307007, -1023319.42367241, -1.2103310777736542, -829815.7741138365, -3346174.443618313, 6.227907821133204, 0.442469859542901, -3.7576564132979744, 9.02891915798632, -229301.44588516196, 0.3522203202869857, -4018607.2891267, 726936.1265967856, -2074543.3883748301, -414910.8385442811, 1.2212261574237941], &#x27;episode_lengths&#x27;: [575, 575, 320, 306, 309, 575, 575, 575, 320, 375, 575, 575, 322, 575, 575, 343, 575, 575, 321, 575, 575, 575, 452, 575, 575, 575, 575, 575, 575, 318, 323, 575, 575, 575, 575, 39, 318, 575, 322, 575, 575, 321, 575, 575, 102, 575, 532, 575, 575, 575, 575, 575, 575, 575, 575, 575, 314, 323, 575, 323, 575, 575, 479, 308, 575, 575, 575, 575, 575, 575, 575, 204, 575, 575, 575, 200, 575, 308, 575, 575, 575, 330, 575, 575, 575, 318, 575, 575, 575, 575, 575, 318, 575, 575, 575, 318, 575, 575, 575, 575]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 0.8659172322685121, &#x27;mean_inference_ms&#x27;: 5.928027824295603, &#x27;mean_action_processing_ms&#x27;: 0.08317311804656224, &#x27;mean_env_wait_ms&#x27;: 5.859601344632639, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0}</td><td style=\"text-align: right;\">             15333.3</td><td style=\"text-align: right;\">           1008.02</td><td style=\"text-align: right;\">       15333.3</td><td>{&#x27;training_iteration_time_ms&#x27;: 998245.632, &#x27;load_time_ms&#x27;: 189.973, &#x27;load_throughput&#x27;: 21055.656, &#x27;learn_time_ms&#x27;: 971832.486, &#x27;learn_throughput&#x27;: 4.116, &#x27;synch_weights_time_ms&#x27;: 31.73}</td><td style=\"text-align: right;\"> 1671153668</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">            60000</td><td style=\"text-align: right;\">                  15</td><td>884a7705  </td><td style=\"text-align: right;\">      10.3752</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.suggest import ConcurrencyLimiter\n",
    "from ray.tune.suggest.optuna import OptunaSearch\n",
    "\n",
    "LR = tune.loguniform(1e-5, 1e-2)\n",
    "GAMMA = tune.uniform(0.8, 0.9999)\n",
    "LAMBDA = tune.uniform(0.1, 0.8)\n",
    "VF_LOSS_COEFF = tune.uniform(0.01, 1.0)\n",
    "ENTROPY_COEFF = tune.uniform(1e-8, 1e-1)\n",
    "\n",
    "checkpoint_metric = 'episode_reward_mean'\n",
    "\n",
    "# Specific configuration keys that will be used during training\n",
    "env_config_training = {\n",
    "    \"TKO_filename\": TKO_train_pickle, \n",
    "    \"STM_filename\": STM_train_pickle,\n",
    "    \"THEP_filename\": THEP_train_pickle, \n",
    "    \"BIM_filename\": BIM_train_pickle,\n",
    "    \"ERF_filename\": ERF_train_pickle, \n",
    "    \"TRI_filename\": TRI_train_pickle,\n",
    "    \"VIRP_filename\": VIRP_train_pickle, \n",
    "    \"AI_filename\": AI_train_pickle,\n",
    "    \"SU_filename\": SU_train_pickle, \n",
    "    \"LTA_filename\": LTA_train_pickle,\n",
    "    \"max_allowed_loss\": 0.10, \n",
    "    \"window_size\": 30 \n",
    "}\n",
    "# Specific configuration keys that will be used during evaluation (only the overridden ones)\n",
    "env_config_evaluation = {\n",
    "    \"TKO_filename\": TKO_test_pickle, \n",
    "    \"STM_filename\": STM_test_pickle,\n",
    "    \"THEP_filename\": THEP_test_pickle, \n",
    "    \"BIM_filename\": BIM_test_pickle,\n",
    "    \"ERF_filename\": ERF_test_pickle, \n",
    "    \"TRI_filename\": TRI_test_pickle,\n",
    "    \"VIRP_filename\": VIRP_test_pickle, \n",
    "    \"AI_filename\": AI_test_pickle,\n",
    "    \"SU_filename\": SU_test_pickle, \n",
    "    \"LTA_filename\": LTA_test_pickle,\n",
    "    \"max_allowed_loss\": 1, \n",
    "    \"window_size\": 30 \n",
    "}\n",
    "# Spec\n",
    "\n",
    "search_alg = OptunaSearch()\n",
    "search_alg = ConcurrencyLimiter(search_alg, max_concurrent=4)\n",
    "\n",
    "scheduler = ASHAScheduler()\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "analysis = tune.run(\n",
    "    \"PPO\",\n",
    "    stop={\n",
    "        \"episode_reward_mean\": 2000,\n",
    "        \"training_iteration\": 35,\n",
    "    },\n",
    "    verbose=3,\n",
    "    config={\n",
    "        \"env\": \"TradingEnv\",\n",
    "        \"env_config\": env_config_training,\n",
    "        \"log_level\": \"ERROR\",\n",
    "        #\"log_level\": \"INFO\",\n",
    "        #\"log_level\": \"DEBUG\",\n",
    "        \"framework\": \"torch\",\n",
    "        \"ignore_worker_failures\": True,\n",
    "        \"num_workers\": 2,\n",
    "        \"num_gpus\": 0,\n",
    "        \"clip_rewards\": True,\n",
    "        \"lr\": LR,\n",
    "        \"lr_schedule\": [\n",
    "            [0, 1e-1],\n",
    "            [int(1e2), 1e-2],\n",
    "            [int(1e3), 1e-3],\n",
    "            [int(1e4), 1e-4],\n",
    "            [int(1e5), 1e-5],\n",
    "            [int(1e6), 1e-6],\n",
    "            [int(1e7), 1e-7]\n",
    "        ],\n",
    "        \"model\": {\n",
    "            \"use_lstm\": True,\n",
    "            \"lstm_cell_size\": 512\n",
    "        },\n",
    "        \"gamma\": GAMMA,\n",
    "        \"observation_filter\": \"MeanStdFilter\",\n",
    "        \"lambda\": LAMBDA,\n",
    "        \"vf_share_layers\": True,\n",
    "        \"vf_loss_coeff\": VF_LOSS_COEFF,\n",
    "        \"entropy_coeff\": ENTROPY_COEFF,\n",
    "        \"evaluation_interval\": 1,  # Run evaluation on every iteration\n",
    "        \"evaluation_config\": {\n",
    "            \"env_config\": env_config_evaluation,  # The dictionary we built before (only the overriding keys to use in evaluation)\n",
    "            \"explore\": False,  # We don't want to explore during evaluation. All actions have to be repeatable.\n",
    "        },\n",
    "    },\n",
    "    metric=checkpoint_metric,\n",
    "    mode=\"max\",\n",
    "    search_alg=search_alg,\n",
    "    scheduler=scheduler,\n",
    "    num_samples=10,  # Samples per hyperparameter combination. More averages out randomness. Less runs faster\n",
    "    #resources_per_trial={\"cpu\": 2},\n",
    "    keep_checkpoints_num=10,  # Keep the last 10 checkpoints\n",
    "    checkpoint_freq=1,  # Do a checkpoint on each iteration (slower but you can pick more finely the checkpoint to use later)\n",
    "    resume=\"AUTO\",\n",
    ")\n",
    "taken = time.time() - start\n",
    "print(f\"Time taken: {taken:.2f} seconds.\")\n",
    "print(f\"Best config: {analysis.best_config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b54388f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('agents/policy_network__48f884a__20221213_175108.hdf5')\n",
    "test = DQNAgent(env1, policy_network = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "076324b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "loaded_ag = DQNAgent(env1).restore('agents/policy_network__48f884a__20221213_175108.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "703f4485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['env', 'n_actions', 'observation_shape', 'policy_network', 'target_network', '_id'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "23ae2083",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DQNAgent' object has no attribute 'test'",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[1;36m  Cell \u001b[1;32mIn [44], line 1\u001b[1;36m\n\u001b[1;33m    test.test()\u001b[1;36m\n",
      "\u001b[1;31mAttributeError\u001b[0m\u001b[1;31m:\u001b[0m 'DQNAgent' object has no attribute 'test'\n"
     ]
    }
   ],
   "source": [
    "test.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ff45f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_quantstats_full_report(env, data, output='dqn_quantstats'):\n",
    "    performance = pd.DataFrame.from_dict(env.action_scheme.portfolio.performance, orient='index')\n",
    "    net_worth = performance['net_worth'].iloc[window_size:]\n",
    "    returns = net_worth.pct_change().iloc[1:]\n",
    "\n",
    "    # WARNING! The dates are fake and default parameters are used!\n",
    "    returns.index = pd.date_range(start=data['date'].iloc[0], freq='1d', periods=returns.size)\n",
    "\n",
    "    qs.reports.full(returns)\n",
    "    qs.reports.html(returns, output=output + '.html')\n",
    "\n",
    "print_quantstats_full_report(env, data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
